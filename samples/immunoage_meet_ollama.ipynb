{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example assumes that you have an [Ollama](https://github.com/ollama/ollama) model running (with `ollama serve`) on some host that is reachable (whether a `localhost` of your computer or some other host with a public IP).\n",
    "As a predictor, we use [txai_omics_3](https://github.com/SermanVS/txai_omics_3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llamba.chatmodels.ollama import OllamaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "chatbot = OllamaModel(url=\"http://127.0.0.1:11434/\", endpoint=\"api/generate\", model=\"llama3\")\n",
    "connection = chatbot.check_connection()\n",
    "print(connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a bioage model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.6.4 to v2.1.4. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint H:\\Lobachevsky\\txai_omics_3\\data\\immuno\\model.ckpt`\n",
      "h:\\Lobachevsky\\llamba\\llamba_env\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: Metric `SpearmanCorrcoef` will save all targets and predictions in the buffer. For large datasets, this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import shap\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "from txai_omics_3.models.tabular.widedeep.ft_transformer import WDFTTransformerModel, FN_CHECKPOINT, FN_SHAP, TRAIN_DATA_PATH\n",
    "from llamba.bioage_model import BioAgeModel\n",
    "\n",
    "# Model\n",
    "fn_model = FN_CHECKPOINT\n",
    "model = WDFTTransformerModel.load_from_checkpoint(checkpoint_path=fn_model)\n",
    "bioage_model = BioAgeModel(model=model)\n",
    "\n",
    "# SHAP\n",
    "fn_shap = FN_SHAP\n",
    "\n",
    "def predict_func(x):\n",
    "    batch = {\n",
    "        'all': torch.from_numpy(np.float32(x)),\n",
    "        'continuous': torch.from_numpy(np.float32(x)),\n",
    "        'categorical': torch.from_numpy(np.int32(x[:, []])),\n",
    "    }\n",
    "    return model(batch).cpu().detach().numpy()\n",
    "with open(fn_shap, 'rb') as handle:\n",
    "    shap_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "my_data = {'CXCL9': 2599.629474, \n",
    "           'CCL22': 820.306524, \n",
    "           'IL6': 0.846377, \n",
    "           'PDGFB': 13400.666359, \n",
    "           'CD40LG': 1853.847406, \n",
    "           'IL27': 1128.886982,\n",
    "           'VEGFA': 153.574220,\n",
    "           'CSF1': 239.627236,\n",
    "           'PDGFA': 1005.844290,\n",
    "           'CXCL10': 228.229829,\n",
    "           'Age': 90.454972 }\n",
    "\n",
    "my_df = pd.DataFrame(my_data, index=[0])\n",
    "\n",
    "# Model data\n",
    "\n",
    "train_data = pd.read_excel(TRAIN_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize a connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llamba.connector import LlambaConnector\n",
    "\n",
    "connector = LlambaConnector(bioage_model=bioage_model, chat_model=chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run an analysis task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your bioage is 79 and your aging acceleration is -11, which means you are ageing slower than normal.\n",
      "\n",
      "Here is some more information about your data. \n",
      "\n",
      "CXCL9: 2599.629474\n",
      "CXCL9 (Chemokine C-X-C Motif Ligand 9) is a member of the CXC chemokine family, involved in immune responses and inflammation. An increased level of CXCL9 typically indicates an active inflammatory response or chronic inflammation, which can be associated with various age-related diseases such as rheumatoid arthritis, atherosclerosis, and cancer. Elevated CXCL9 levels may also be seen in conditions like cardiovascular disease, diabetes, and Alzheimer's disease.\n",
      "\n",
      "CD40LG: 1853.847406\n",
      "CD40LG (also known as TNFSF5) is a protein encoded by the TNFSF5 gene, which is a member of the tumor necrosis factor receptor superfamily. It plays a crucial role in B cell development and activation.\n",
      "\n",
      "An increased level of CD40LG in blood or tissue can indicate an abnormal immune response, such as autoimmune disorders (e.g., lupus), lymphoid neoplasms (e.g., lymphoma), or chronic infections (e.g., HIV). In older adults, elevated CD40LG levels may be associated with age-related immune dysregulation and increased risk of age-related diseases, including atherosclerosis and Alzheimer's disease.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = connector.analyze(data=my_df, shap_dict=shap_dict)\n",
    "print(res['analysis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamba_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
