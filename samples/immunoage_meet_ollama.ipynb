{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example assumes that you have an [Ollama](https://github.com/ollama/ollama) model running (with `ollama serve`) on some host that is reachable (whether a `localhost` of your computer or some other host with a public IP).\n",
    "As a predictor, we use [txai_omics_3](https://github.com/SermanVS/txai_omics_3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llamba.chatmodels.ollama import OllamaModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "chatbot = OllamaModel(url=\"http://127.0.0.1:11434/\", endpoint=\"api/generate\", model=\"llama3\", num_threads=1, check_connection_timeout=5, request_timeout=15)\n",
    "connection = chatbot.check_connection()\n",
    "print(connection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a bioage model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Lightning automatically upgraded your loaded checkpoint from v1.6.4 to v2.1.4. To apply the upgrade to your files permanently, run `python -m pytorch_lightning.utilities.upgrade_checkpoint H:\\Lobachevsky\\txai_omics_3\\data\\immuno\\model.ckpt`\n",
      "h:\\Lobachevsky\\llamba\\llamba_env\\Lib\\site-packages\\torchmetrics\\utilities\\prints.py:43: UserWarning: Metric `SpearmanCorrcoef` will save all targets and predictions in the buffer. For large datasets, this may lead to large memory footprint.\n",
      "  warnings.warn(*args, **kwargs)  # noqa: B028\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import shap\n",
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "from txai_omics_3.models.tabular.widedeep.ft_transformer import WDFTTransformerModel, FN_CHECKPOINT, FN_SHAP, TRAIN_DATA_PATH\n",
    "from llamba.bioage_model import BioAgeModel\n",
    "\n",
    "# Model\n",
    "fn_model = FN_CHECKPOINT\n",
    "model = WDFTTransformerModel.load_from_checkpoint(checkpoint_path=fn_model)\n",
    "bioage_model = BioAgeModel(model=model)\n",
    "\n",
    "# SHAP\n",
    "fn_shap = FN_SHAP\n",
    "\n",
    "def predict_func(x):\n",
    "    batch = {\n",
    "        'all': torch.from_numpy(np.float32(x)),\n",
    "        'continuous': torch.from_numpy(np.float32(x)),\n",
    "        'categorical': torch.from_numpy(np.int32(x[:, []])),\n",
    "    }\n",
    "    return model(batch).cpu().detach().numpy()\n",
    "with open(fn_shap, 'rb') as handle:\n",
    "    shap_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "my_data = {'CXCL9': 2599.629474, \n",
    "           'CCL22': 820.306524, \n",
    "           'IL6': 0.846377, \n",
    "           'PDGFB': 13400.666359, \n",
    "           'CD40LG': 1853.847406, \n",
    "           'IL27': 1128.886982,\n",
    "           'VEGFA': 153.574220,\n",
    "           'CSF1': 239.627236,\n",
    "           'PDGFA': 1005.844290,\n",
    "           'CXCL10': 228.229829,\n",
    "           'Age': 90.454972 }\n",
    "\n",
    "my_df = pd.DataFrame(my_data, index=[0])\n",
    "\n",
    "# Model data\n",
    "\n",
    "train_data = pd.read_excel(TRAIN_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize a connector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llamba.connector import LlambaConnector\n",
    "\n",
    "connector = LlambaConnector(bioage_model=bioage_model, chat_model=chatbot)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run an analysis task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your bioage is 79 and your aging acceleration is -11, which means you are ageing slower than normal.\n",
      "\n",
      "Here is some more information about your data. \n",
      "\n",
      "CXCL9: 2599.629474\n",
      "CXCL9, also known as Mig or Cytokine-XC motif chemokine 9, is a member of the CC chemokine family. It is involved in the activation and migration of immune cells such as T-cells and NK cells.\n",
      "\n",
      "An increased level of CXCL9 has been associated with various inflammatory diseases, including rheumatoid arthritis, psoriasis, and multiple sclerosis. In older adults, elevated levels of CXCL9 have been linked to age-related conditions like atherosclerosis, osteoporosis, and sarcopenia. In particular, it may contribute to the development of frailty and functional decline in older adults by promoting inflammation and tissue damage.\n",
      "\n",
      "CD40LG: 1853.847406\n",
      "CD40LG, also known as TNFSF5, is a receptor protein that plays a crucial role in B cell activation, proliferation, and survival. It is a ligand for the CD40 receptor.\n",
      "\n",
      "An increased level of CD40LG can be associated with autoimmune diseases such as lupus or rheumatoid arthritis, where it may contribute to the pathogenesis by promoting the activation and proliferation of autoreactive B cells. In healthy individuals, elevated levels of CD40LG have been linked to immune senescence, which is characterized by a decline in immune function with aging.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = connector.analyze(data=my_df, shap_dict=shap_dict)\n",
    "print(res['analysis'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamba_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
